{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNt++W3D6ucLlt+wOP2k83O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A0-UaxVli8EF","executionInfo":{"status":"ok","timestamp":1683990600632,"user_tz":-330,"elapsed":16983,"user":{"displayName":"Rutuja Kadam","userId":"13945739489036101787"}},"outputId":"a5a2cda0-5fa5-4bd0-f253-c72ca19a3a6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 14476184848920465612\n"," xla_global_id: -1,\n"," name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 14343274496\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 8480291023511790585\n"," physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n"," xla_global_id: 416903419]"]},"metadata":{},"execution_count":1}],"source":["from google.colab import drive \n","drive.mount('/content/drive', force_remount=True)\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","import random\n","import cv2\n","import os\n","import tensorflow as tf\n","from tqdm import tqdm\n","\n","import tensorflow as tf\n","tf.test.gpu_device_name()\n","from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"]},{"cell_type":"code","source":["good_frames = '/content/drive/MyDrive/MajorP/datax/sharp/PNEUMONIA'\n","blur_frames= '/content/drive/MyDrive/MajorP/datax/blur'"],"metadata":{"id":"YSInw3SVjbzP","executionInfo":{"status":"ok","timestamp":1683990605040,"user_tz":-330,"elapsed":709,"user":{"displayName":"Rutuja Kadam","userId":"13945739489036101787"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["clean_frames = []\n","for file in tqdm(sorted(os.listdir(good_frames))):\n","  if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n","    image = tf.keras.preprocessing.image.load_img(good_frames + '/' + file, target_size=(224,224))\n","    image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n","    clean_frames.append(image)\n","\n","clean_frames = np.array(clean_frames)\n","blurry_frames = []\n","for file in tqdm(sorted(os.listdir(blur_frames))):\n","  if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n","    image = tf.keras.preprocessing.image.load_img(blur_frames + '/' + file, target_size=(224,224))\n","    image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n","    blurry_frames.append(image)\n","\n","blurry_frames = np.array(blurry_frames)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MhcQ07YojkX6","executionInfo":{"status":"ok","timestamp":1683990223124,"user_tz":-330,"elapsed":125430,"user":{"displayName":"Rutuja Kadam","userId":"13945739489036101787"}},"outputId":"ab449d48-2b33-42a7-f378-73f2ae70798d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 3875/3875 [00:46<00:00, 83.94it/s] \n","100%|██████████| 3875/3875 [01:16<00:00, 50.90it/s]\n"]}]},{"cell_type":"code","source":["x = clean_frames;\n","y = blurry_frames;"],"metadata":{"id":"omWbArISpCjh","executionInfo":{"status":"ok","timestamp":1683990269757,"user_tz":-330,"elapsed":7,"user":{"displayName":"Rutuja Kadam","userId":"13945739489036101787"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"4la7JosGpH-3","executionInfo":{"status":"ok","timestamp":1683990287407,"user_tz":-330,"elapsed":721,"user":{"displayName":"Rutuja Kadam","userId":"13945739489036101787"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"],"metadata":{"id":"wWRTwEs3oTC0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","# import numpy as np\n","# import tensorflow as tf\n","# from tqdm import tqdm\n","# from sklearn.model_selection import train_test_split\n","\n","# def load_images(image_dir):\n","#     for file in tqdm(sorted(os.listdir(image_dir))):\n","#         if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n","#             image = tf.keras.preprocessing.image.load_img(os.path.join(image_dir, file), target_size=(224,224))\n","#             image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n","#             yield image\n","\n","# # Load clean frames using a generator function\n","# clean_gen = load_images(good_frames)\n","# clean_frames = np.array([next(clean_gen) for _ in range(len(os.listdir(good_frames)))])\n","\n","# # Load blurry frames using a generator function\n","# blurry_gen = load_images(blur_frames)\n","# blurry_frames = np.array([next(blurry_gen) for _ in range(len(os.listdir(blur_frames)))])\n","\n","# # Split the data into training and testing sets using generator functions\n","# batch_size = 32\n","# train_gen = ((x, y) for x, y in zip(clean_frames[:len(clean_frames)//5*4], blurry_frames[:len(blurry_frames)//5*4]))\n","# test_gen = ((x, y) for x, y in zip(clean_frames[len(clean_frames)//5*4:], blurry_frames[len(blurry_frames)//5*4:]))\n","# train_ds = tf.data.Dataset.from_generator(lambda: train_gen, output_types=(tf.float32, tf.float32))\n","# train_ds = train_ds.batch(batch_size)\n","# test_ds = tf.data.Dataset.from_generator(lambda: test_gen, output_types=(tf.float32, tf.float32))\n","# test_ds = test_ds.batch(batch_size)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"cbXutT6QqP-O","executionInfo":{"status":"error","timestamp":1683990661086,"user_tz":-330,"elapsed":43034,"user":{"displayName":"Rutuja Kadam","userId":"13945739489036101787"}},"outputId":"09765309-8674-49f6-b8f4-a1303017542d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 3111/3875 [00:41<00:10, 74.60it/s] \n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-e479ca6b464b>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Load clean frames using a generator function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mclean_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mclean_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_gen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Load blurry frames using a generator function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-e479ca6b464b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Load clean frames using a generator function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mclean_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mclean_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_gen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Load blurry frames using a generator function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-e479ca6b464b>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(image_dir)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         raise TypeError(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","import os\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout\n","\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","\n","# Load sharp and blur images\n","sharp_images = []\n","blur_images = []\n","\n","for file in os.listdir('/content/drive/MyDrive/MajorP/datax/sharp/PNEUMONIA'):\n","    img = cv2.imread(os.path.join('/content/drive/MyDrive/MajorP/datax/sharp/PNEUMONIA', file))\n","    img = cv2.resize(img, (224, 224))\n","    img = img/255.0\n","    sharp_images.append(img)\n","    \n","for file in os.listdir('/content/drive/MyDrive/MajorP/datax/blur'):\n","    img = cv2.imread(os.path.join('/content/drive/MyDrive/MajorP/datax/blur', file))\n","    img = cv2.resize(img, (224, 224))\n","    img = img/255.0\n","    blur_images.append(img)\n","\n","sharp_images = np.array(sharp_images)\n","blur_images = np.array(blur_images)\n","\n","# Split into train and validation sets\n","train_sharp, val_sharp, train_blur, val_blur = train_test_split(sharp_images, blur_images, test_size=0.2, random_state=42)\n","\n","\n"],"metadata":{"id":"0vIZY1bPknqp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = Input(shape=(224, 224, 3))\n","\n","conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n","conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n","pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n","conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n","pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n","conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n","pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n","conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n","drop4 = Dropout(0.5)(conv4)\n","pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n","conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n","drop5 = Dropout(0.5)(conv5)\n","\n","up6 = Conv2D(512, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))\n","merge6 = concatenate([drop4, up6], axis=3)\n","conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n","conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n","\n","up7 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))\n","merge7 = concatenate([conv3, up7], axis=3)\n","conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n","conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n","\n","up8 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))\n","merge8 = concatenate([conv2, up8], axis=3)\n","conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n","conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n","\n","up9 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))\n","merge9 = concatenate([conv1, up9], axis=3)\n","conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n","conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n","\n","conv10 = Conv2D(3, 1, activation='sigmoid')(conv9)\n","\n","\n","model1 = Model(inputs=inputs, outputs=conv10)\n","h=1\n","model1.summary()"],"metadata":{"id":"fn5vwikfl7XM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n","\n","def train(model, train_sharp, train_blur, val_sharp, val_blur, batch_size, epochs):\n","    opt = Adam(lr=1e-4)\n","    model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n","    checkpoint = ModelCheckpoint('model1.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","    callbacks_list = [checkpoint]\n","    model.fit(train_blur, train_sharp, batch_size=batch_size, epochs=epochs, validation_data=(val_blur, val_sharp), callbacks=callbacks_list)\n","    model.save(\"/content/drive/MyDrive/idb/saved_model/Unet/unetkeras1.h5\")\n","\n","def validate(model, val_sharp, val_blur):\n","    opt = Adam(lr=1e-4)\n","    model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n","    model.load_weights('model1.h5')\n","    loss, acc = model1.evaluate(val_blur, val_sharp)\n","    print('Validation Loss:', loss)\n","    print('Validation Accuracy:', acc)\n","\n","    pred_sharp = model.predict(val_blur)\n","    psnr = peak_signal_noise_ratio(val_sharp, pred_sharp)\n","    ssim = structural_similarity(val_sharp, pred_sharp, multichannel=True)\n","    print('PSNR:', psnr)\n","    print('SSIM:', ssim)\n","    return loss, acc"],"metadata":{"id":"XYb_0xt1l_P-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(model1, train_sharp, train_blur, val_sharp, val_blur, batch_size=32, epochs=15)\n","validate(model1, val_sharp, val_blur)"],"metadata":{"id":"ZJH-5w3VmDM2"},"execution_count":null,"outputs":[]}]}